{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "This coding environment will be used to train the agent for the project.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "The next code cell installs a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 2.0.10 which is incompatible.\u001b[0m\n",
      "CPU times: user 696 ms, sys: 117 ms, total: 813 ms\n",
      "Wall time: 51.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_env(unity_file):\n",
    "    # Initialize the environment\n",
    "    env = UnityEnvironment(file_name=unity_file)\n",
    "\n",
    "    # Get default brain\n",
    "    brain_name = env.brain_names[0]\n",
    "    brain = env.brains[brain_name]\n",
    "\n",
    "    # Get state and action spaces\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    state_size = env_info.vector_observations.shape[1]\n",
    "    action_size = brain.vector_action_space_size\n",
    "    n_agents = len(env_info.agents)\n",
    "    \n",
    "    print('State size: ', state_size)\n",
    "    print('Action size: ', action_size)\n",
    "    print('Number of agents: ', n_agents)\n",
    "    \n",
    "    return env, brain_name, brain, state_size, action_size, n_agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size:  33\n",
      "Action size:  4\n",
      "Number of agents:  1\n"
     ]
    }
   ],
   "source": [
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "unity_file = '/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64'\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "# unity_file='/data/Reacher_Linux_NoVis/Reacher.x86_64'\n",
    "\n",
    "env, brain_name, brain, state_size, action_size, n_agents = initialize_env(unity_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Let's print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -6.30408478e+00  -1.00000000e+00\n",
      "  -4.92529202e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -5.33014059e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'\n",
    "      .format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "**In this coding environment, we will not be able to watch the agents while they are training**, and we should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.0. Number of episodes: 1000.\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "i_episode = 0\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    i_episode += 1\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}. Number of episodes: {}.'\n",
    "      .format(np.mean(scores), i_episode-1))\n",
    "\n",
    "# Just to be sure they're not used any more\n",
    "del states, actions, next_states, rewards, dones, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- In oder to watch the agents while they are training: **_After training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Submission\n",
    "\n",
    "> The following solution is based on the code provided in [Udacity ddpg-bipedal](https://github.com/udacity/deep-reinforcement-learning/blob/master/ddpg-bipedal/DDPG.ipynb). In particular, it uses the files [model.py](https://github.com/udacity/deep-reinforcement-learning/blob/master/ddpg-bipedal/model.py) and [ddpg_agent/py](https://github.com/udacity/deep-reinforcement-learning/blob/master/ddpg-bipedal/ddpg_agent.py), as well as the code provided in the training loop `ddpg()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime, time\n",
    "import torch\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from workspace_utils import active_session\n",
    "\n",
    "from ddpg_agent import Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Algorithm\n",
    "\n",
    "TODO - Describe DDPG...\n",
    "\n",
    "####  Neural Network Architecture\n",
    "\n",
    "TODO - Finalize...\n",
    "After trying the initial architecture from the Udacity bipolar walker, and reading in the student hub I adapted the model as follows:\n",
    "\n",
    "For the **actor** I added another fully connected layer with 128 neurons.\n",
    "This results in the following number of neurons on each layer then (input, FC1, FC2, output): `33-256-128-4`.\n",
    "Besides, a batch normalization layer is being introduced in between the fully connected layers, to help normalize the activation across the batch of samples from the replay buffer\n",
    "\n",
    "The **critic** is adjusted in the following way:\n",
    "128-128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg(env, brain_name, agent, n_agents,\n",
    "         n_episodes=750, max_t=700):\n",
    "    \n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    last_average_score = 0\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        \n",
    "        t_start = datetime.datetime.now()\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations[0]\n",
    "        agent.reset()\n",
    "        score = 0\n",
    "        \n",
    "        for t in range(max_t):\n",
    "            print('\\rEpisode {}/{}, t: {}/{}'\n",
    "                  .format(i_episode, n_episodes, t, max_t), end=\"\")\n",
    "            action = agent.act(state)\n",
    "            \n",
    "            env_info = env.step(action)[brain_name]     # send all actions to the environment\n",
    "            next_state = env_info.vector_observations[0] # get next state (for each agent)\n",
    "            reward = env_info.rewards[0]                 # get reward (for each agent)\n",
    "            done = env_info.local_done[0]                # see if episode finished\n",
    "\n",
    "            agent.step(state, action, reward, next_state, done, t)\n",
    "            \n",
    "            score += reward\n",
    "            state = next_state                           # roll over states to next time step\n",
    "            \n",
    "            if done:                                     # exit loop if episode finished\n",
    "                break\n",
    "                \n",
    "        scores_deque.append(score)\n",
    "        scores.append(score)\n",
    "        \n",
    "        t_episode = datetime.datetime.now() - t_start\n",
    "        average_score = np.mean(scores_deque)\n",
    "        improvement = average_score - last_average_score\n",
    "        last_average_score = average_score\n",
    "        print('\\rEpisode: {}, Average Score: {:.2f} ({:.2f}), Score: {:.2f}, time: {}'\n",
    "              .format(i_episode, average_score, improvement, score, t_episode), end=\"\")\n",
    "\n",
    "        # average_score should be above 5. after 100 episodes! Abort if not...\n",
    "        if i_episode >= 100:\n",
    "            if average_score < 5.:\n",
    "                print('\\nAverage score is only {:.3f} after {} episodes, '\\\n",
    "                    'hence aborting this run!\\n'.format(average_score, i_episode))\n",
    "                break\n",
    "        \n",
    "        if i_episode % 100 == 0:\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            print('\\nEpisode: {}, Average Score: {:.2f}\\n'\n",
    "                  .format(i_episode, average_score))\n",
    "\n",
    "        if np.mean(scores_deque) >= 30.0:\n",
    "            print('\\n\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'\n",
    "                  .format(i_episode, average_score))\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor_solution.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic_solution.pth')\n",
    "            break\n",
    "            \n",
    "    return scores, average_score, t_episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have several hyperparameters for training the DDPG algorithm.\n",
    "Some of them are listed in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 400  # Should be enough to solve this!\n",
    "BUFFER_SIZE = [int(1e5), int(1e7)]\n",
    "BATCH_SIZE = [64, 128, 256]\n",
    "GAMMA = .99\n",
    "TAU = 1e-3\n",
    "LEARN_RATE = [1e-3, 1e-4]\n",
    "WEIGHT_DECAY = 0.0\n",
    "SEED = 2\n",
    "MAX_T = [1000, 3000]\n",
    "NEURONS = [128, 256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter grid search\n",
    "\n",
    "Manual try & error of a few hyperparameters did unfortunately not lead to a succesful model.\n",
    "Hence, in order to find the best hyperparameters, we define some possible values and perform a grid search over the hyperparameter space.\n",
    "It shall be pointed out, that the `ddpg()` method exits, if the score did not reach at least `5.0` after `100` episodes!\n",
    "\n",
    "First, let's create all combinations of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will be testing 48 combinations of hyperparameters!\n",
      "3 random Examples:\n",
      "Combination(buffer_size=100000, batch_size=128, learn_rate=0.001, max_t=3000, neurons=128)\n",
      "Combination(buffer_size=100000, batch_size=64, learn_rate=0.0001, max_t=3000, neurons=128)\n",
      "Combination(buffer_size=10000000, batch_size=128, learn_rate=0.001, max_t=1000, neurons=256)\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "from itertools import product, starmap\n",
    "import pickle\n",
    "\n",
    "def named_product(**items):\n",
    "    Combination = namedtuple('Combination', items.keys())\n",
    "    return starmap(Combination, product(*items.values()))\n",
    "\n",
    "hyperparameter_combinations = []\n",
    "for combination in named_product(buffer_size=BUFFER_SIZE,\n",
    "                                 batch_size=BATCH_SIZE,\n",
    "                                 learn_rate=LEARN_RATE,\n",
    "                                 max_t=MAX_T,\n",
    "                                 neurons=NEURONS):\n",
    "    # print(combination)\n",
    "    hyperparameter_combinations.append(combination)\n",
    "\n",
    "len_hyperparameter_combinations = len(hyperparameter_combinations)\n",
    "print('We will be testing {} combinations of hyperparameters!'\n",
    "      .format(len_hyperparameter_combinations))\n",
    "\n",
    "# Let's check a few of them\n",
    "num_examples = 3\n",
    "print('{} random Examples:'.format(num_examples))\n",
    "for _ in range(num_examples):\n",
    "    print(hyperparameter_combinations[random.randint(0, len_hyperparameter_combinations-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_grid_search = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 9.54 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "agent = None\n",
    "\n",
    "scores_grid_search = []\n",
    "missing_combinations = [12, 14, 15, 22, 23, 24, 25, 26, 27, 28, 38]\n",
    "\n",
    "if run_grid_search:\n",
    "    with active_session():\n",
    "        for i, hyperparameters in enumerate(hyperparameter_combinations):\n",
    "            id = i+1\n",
    "            if id not in missing_combinations:\n",
    "                continue\n",
    "\n",
    "            print('Testing following hyperparameters ({}/{}):\\n{}\\n'\n",
    "                  .format(id, len(hyperparameter_combinations), hyperparameters))\n",
    "\n",
    "            # Delete any existing agent\n",
    "            if agent is not None:\n",
    "                del agent\n",
    "\n",
    "            # Initialize agent\n",
    "            agent = Agent(state_size,\n",
    "                          action_size,\n",
    "                          n_agents,\n",
    "                          buffer_size=hyperparameters.buffer_size,\n",
    "                          batch_size=hyperparameters.batch_size,\n",
    "                          gamma=GAMMA,\n",
    "                          tau=TAU,\n",
    "                          lr_actor=hyperparameters.learn_rate,\n",
    "                          lr_critic=hyperparameters.learn_rate,\n",
    "                          weight_decay=WEIGHT_DECAY,\n",
    "                          neurons=hyperparameters.neurons,\n",
    "                          random_seed=SEED)\n",
    "\n",
    "            # Run training\n",
    "            scores, average_score, t_episode = ddpg(env, brain_name, agent, n_agents,\n",
    "                                                    n_episodes=N, max_t=hyperparameters.max_t)\n",
    "\n",
    "            # Save results\n",
    "            print('Saving results...')\n",
    "            scores_grid_search.append((hyperparameters, t_episode, scores, average_score))\n",
    "            # TODO Write directly to CSV file..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the cell above has been manually put into the file `screen_scrape.txt`, and then processed by `create_csv.py`.\n",
    "Resulting CSV file will be imported in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>buffer_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learn_rate</th>\n",
       "      <th>max_t</th>\n",
       "      <th>neurons</th>\n",
       "      <th>episodes</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>27</td>\n",
       "      <td>10000000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>1.37</td>\n",
       "      <td>00:00:14.567689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>41</td>\n",
       "      <td>10000000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>1.29</td>\n",
       "      <td>00:00:21.143977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>37</td>\n",
       "      <td>10000000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>1.28</td>\n",
       "      <td>00:00:17.895239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>100000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3000</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>1.27</td>\n",
       "      <td>00:00:20.971953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>12</td>\n",
       "      <td>100000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3000</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>1.20</td>\n",
       "      <td>00:00:16.543660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>33</td>\n",
       "      <td>10000000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>1.19</td>\n",
       "      <td>00:00:17.244626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>28</td>\n",
       "      <td>10000000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3000</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>1.18</td>\n",
       "      <td>00:00:14.360792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>26</td>\n",
       "      <td>10000000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1000</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>1.18</td>\n",
       "      <td>00:00:15.332227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>44</td>\n",
       "      <td>10000000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3000</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>1.16</td>\n",
       "      <td>00:00:19.806695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>42</td>\n",
       "      <td>10000000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1000</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>1.11</td>\n",
       "      <td>00:00:19.747336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>34</td>\n",
       "      <td>10000000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1000</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>1.08</td>\n",
       "      <td>00:00:17.614199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>36</td>\n",
       "      <td>10000000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3000</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>1.05</td>\n",
       "      <td>00:00:17.472221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>14</td>\n",
       "      <td>100000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>1.04</td>\n",
       "      <td>00:00:16.458676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>25</td>\n",
       "      <td>10000000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>00:00:14.644425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>43</td>\n",
       "      <td>10000000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>0.96</td>\n",
       "      <td>00:00:19.380926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30</td>\n",
       "      <td>10000000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>0.92</td>\n",
       "      <td>00:00:14.338409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>100000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1000</td>\n",
       "      <td>256</td>\n",
       "      <td>50</td>\n",
       "      <td>0.91</td>\n",
       "      <td>00:00:17.601879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>22</td>\n",
       "      <td>100000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>0.88</td>\n",
       "      <td>00:00:20.228565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18</td>\n",
       "      <td>100000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1000</td>\n",
       "      <td>256</td>\n",
       "      <td>50</td>\n",
       "      <td>0.84</td>\n",
       "      <td>00:00:20.787934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17</td>\n",
       "      <td>100000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>0.83</td>\n",
       "      <td>00:00:20.479269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>29</td>\n",
       "      <td>10000000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>0.78</td>\n",
       "      <td>00:00:15.984810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>100000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>0.76</td>\n",
       "      <td>00:00:17.392905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19</td>\n",
       "      <td>100000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3000</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>00:00:19.799508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3000</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>0.74</td>\n",
       "      <td>00:00:14.998592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>100000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3000</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>0.72</td>\n",
       "      <td>00:00:15.916030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>40</td>\n",
       "      <td>10000000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3000</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>0.72</td>\n",
       "      <td>00:00:18.075663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>100000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>256</td>\n",
       "      <td>50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>00:00:15.915925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>45</td>\n",
       "      <td>10000000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>0.68</td>\n",
       "      <td>00:00:19.260393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>38</td>\n",
       "      <td>10000000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>0.67</td>\n",
       "      <td>00:00:16.133522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46</td>\n",
       "      <td>10000000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>0.65</td>\n",
       "      <td>00:00:19.766807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1000</td>\n",
       "      <td>256</td>\n",
       "      <td>50</td>\n",
       "      <td>0.63</td>\n",
       "      <td>00:00:14.555644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>100000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3000</td>\n",
       "      <td>256</td>\n",
       "      <td>50</td>\n",
       "      <td>0.62</td>\n",
       "      <td>00:00:15.527081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>35</td>\n",
       "      <td>10000000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>0.57</td>\n",
       "      <td>00:00:17.164317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>32</td>\n",
       "      <td>10000000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3000</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>0.56</td>\n",
       "      <td>00:00:15.346309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>0.46</td>\n",
       "      <td>00:00:14.470509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>100000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3000</td>\n",
       "      <td>256</td>\n",
       "      <td>50</td>\n",
       "      <td>0.45</td>\n",
       "      <td>00:00:15.713651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>48</td>\n",
       "      <td>10000000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3000</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>0.41</td>\n",
       "      <td>00:00:20.135187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>24</td>\n",
       "      <td>100000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3000</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>0.39</td>\n",
       "      <td>00:00:20.332723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>100000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>0.38</td>\n",
       "      <td>00:00:16.483312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>100000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>0.29</td>\n",
       "      <td>00:00:15.633495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>23</td>\n",
       "      <td>100000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>0.20</td>\n",
       "      <td>00:00:20.001375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>39</td>\n",
       "      <td>10000000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>0.19</td>\n",
       "      <td>00:00:17.384141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31</td>\n",
       "      <td>10000000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>0.16</td>\n",
       "      <td>00:00:15.489140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>47</td>\n",
       "      <td>10000000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>0.13</td>\n",
       "      <td>00:00:19.581966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21</td>\n",
       "      <td>100000</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>00:00:20.144430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>15</td>\n",
       "      <td>100000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>0.09</td>\n",
       "      <td>00:00:16.103063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>100000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3000</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>0.07</td>\n",
       "      <td>00:00:16.152890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>100000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3000</td>\n",
       "      <td>256</td>\n",
       "      <td>50</td>\n",
       "      <td>0.05</td>\n",
       "      <td>00:00:17.303011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  buffer_size  batch_size  learn_rate  max_t  neurons  episodes  \\\n",
       "45  27     10000000          64      0.0010   3000      128       100   \n",
       "29  41     10000000         256      0.0010   1000      128       100   \n",
       "26  37     10000000         128      0.0001   1000      128       100   \n",
       "16  20       100000         256      0.0010   3000      256       100   \n",
       "37  12       100000         128      0.0010   3000      256       100   \n",
       "22  33     10000000         128      0.0010   1000      128       100   \n",
       "46  28     10000000          64      0.0010   3000      256       100   \n",
       "44  26     10000000          64      0.0010   1000      256       100   \n",
       "32  44     10000000         256      0.0010   3000      256       100   \n",
       "30  42     10000000         256      0.0010   1000      256       100   \n",
       "23  34     10000000         128      0.0010   1000      256       100   \n",
       "25  36     10000000         128      0.0010   3000      256       100   \n",
       "38  14       100000         128      0.0001   1000      256       100   \n",
       "43  25     10000000          64      0.0010   1000      128       100   \n",
       "31  43     10000000         256      0.0010   3000      128       100   \n",
       "19  30     10000000          64      0.0001   1000      256       100   \n",
       "9   10       100000         128      0.0010   1000      256        50   \n",
       "40  22       100000         256      0.0001   1000      256       100   \n",
       "14  18       100000         256      0.0010   1000      256        50   \n",
       "13  17       100000         256      0.0010   1000      128        50   \n",
       "18  29     10000000          64      0.0001   1000      128       100   \n",
       "8    9       100000         128      0.0010   1000      128        50   \n",
       "15  19       100000         256      0.0010   3000      128        50   \n",
       "2    3       100000          64      0.0010   3000      128        50   \n",
       "10  11       100000         128      0.0010   3000      128        50   \n",
       "28  40     10000000         128      0.0001   3000      256       100   \n",
       "5    6       100000          64      0.0001   1000      256        50   \n",
       "33  45     10000000         256      0.0001   1000      128       100   \n",
       "47  38     10000000         128      0.0001   1000      256       100   \n",
       "34  46     10000000         256      0.0001   1000      256       100   \n",
       "1    2       100000          64      0.0010   1000      256        50   \n",
       "3    4       100000          64      0.0010   3000      256        50   \n",
       "24  35     10000000         128      0.0010   3000      128       100   \n",
       "21  32     10000000          64      0.0001   3000      256       100   \n",
       "0    1       100000          64      0.0010   1000      128        50   \n",
       "7    8       100000          64      0.0001   3000      256        50   \n",
       "36  48     10000000         256      0.0001   3000      256       100   \n",
       "42  24       100000         256      0.0001   3000      256       100   \n",
       "11  13       100000         128      0.0001   1000      128        50   \n",
       "4    5       100000          64      0.0001   1000      128        50   \n",
       "41  23       100000         256      0.0001   3000      128       100   \n",
       "27  39     10000000         128      0.0001   3000      128       100   \n",
       "20  31     10000000          64      0.0001   3000      128       100   \n",
       "35  47     10000000         256      0.0001   3000      128       100   \n",
       "17  21       100000         256      0.0001   1000      128        50   \n",
       "39  15       100000         128      0.0001   3000      128       100   \n",
       "6    7       100000          64      0.0001   3000      128        50   \n",
       "12  16       100000         128      0.0001   3000      256        50   \n",
       "\n",
       "    avg_score             time  \n",
       "45       1.37  00:00:14.567689  \n",
       "29       1.29  00:00:21.143977  \n",
       "26       1.28  00:00:17.895239  \n",
       "16       1.27  00:00:20.971953  \n",
       "37       1.20  00:00:16.543660  \n",
       "22       1.19  00:00:17.244626  \n",
       "46       1.18  00:00:14.360792  \n",
       "44       1.18  00:00:15.332227  \n",
       "32       1.16  00:00:19.806695  \n",
       "30       1.11  00:00:19.747336  \n",
       "23       1.08  00:00:17.614199  \n",
       "25       1.05  00:00:17.472221  \n",
       "38       1.04  00:00:16.458676  \n",
       "43       0.99  00:00:14.644425  \n",
       "31       0.96  00:00:19.380926  \n",
       "19       0.92  00:00:14.338409  \n",
       "9        0.91  00:00:17.601879  \n",
       "40       0.88  00:00:20.228565  \n",
       "14       0.84  00:00:20.787934  \n",
       "13       0.83  00:00:20.479269  \n",
       "18       0.78  00:00:15.984810  \n",
       "8        0.76  00:00:17.392905  \n",
       "15       0.75  00:00:19.799508  \n",
       "2        0.74  00:00:14.998592  \n",
       "10       0.72  00:00:15.916030  \n",
       "28       0.72  00:00:18.075663  \n",
       "5        0.70  00:00:15.915925  \n",
       "33       0.68  00:00:19.260393  \n",
       "47       0.67  00:00:16.133522  \n",
       "34       0.65  00:00:19.766807  \n",
       "1        0.63  00:00:14.555644  \n",
       "3        0.62  00:00:15.527081  \n",
       "24       0.57  00:00:17.164317  \n",
       "21       0.56  00:00:15.346309  \n",
       "0        0.46  00:00:14.470509  \n",
       "7        0.45  00:00:15.713651  \n",
       "36       0.41  00:00:20.135187  \n",
       "42       0.39  00:00:20.332723  \n",
       "11       0.38  00:00:16.483312  \n",
       "4        0.29  00:00:15.633495  \n",
       "41       0.20  00:00:20.001375  \n",
       "27       0.19  00:00:17.384141  \n",
       "20       0.16  00:00:15.489140  \n",
       "35       0.13  00:00:19.581966  \n",
       "17       0.10  00:00:20.144430  \n",
       "39       0.09  00:00:16.103063  \n",
       "6        0.07  00:00:16.152890  \n",
       "12       0.05  00:00:17.303011  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "grid_search = pd.read_csv(\"grid_search.csv\")\n",
    "grid_search['time'] = pd.to_datetime(grid_search['time']).dt.time\n",
    "grid_search.sort_values(by='avg_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the table above, none of the hyperparameter combinations results in a score of more than `1.37` after the first `100` episodes.\n",
    "Several of the training runs have already been aborted after `50` episodes, since the score did not reach `1.0` by then.\n",
    "\n",
    "It is expected, that training reaches at least a score of `5.0` after `100` episodes, as can be seen in other students' submissions and as discussed on the Udacity Nanodegree Slack channnel.\n",
    "This holds even for the single agent environment.\n",
    "Hence, an error in the current implementation of the training algorithm is suspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(scores):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(len(scores)), scores)\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.show()\n",
    "\n",
    "plot_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, we can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
